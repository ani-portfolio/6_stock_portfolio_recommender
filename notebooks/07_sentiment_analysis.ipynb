{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockSentimentAnalyzer:\n",
    "    def __init__(self, news_api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the sentiment analyzer with NewsAPI key and HuggingFace model.\n",
    "        \n",
    "        Args:\n",
    "            news_api_key (str): Your NewsAPI key\n",
    "        \"\"\"\n",
    "        self.news_api_key = news_api_key\n",
    "        self.base_url = \"https://newsapi.org/v2/everything\"\n",
    "        \n",
    "        # Initialize HuggingFace sentiment analysis pipeline\n",
    "        # Using FinBERT model specifically trained on financial text\n",
    "        try:\n",
    "            self.sentiment_analyzer = pipeline(\n",
    "                \"sentiment-analysis\",\n",
    "                model=\"ProsusAI/finbert\",\n",
    "                tokenizer=\"ProsusAI/finbert\"\n",
    "            )\n",
    "            logger.info(\"FinBERT model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"FinBERT model failed to load: {e}. Using default model.\")\n",
    "            # Fallback to general sentiment model\n",
    "            self.sentiment_analyzer = pipeline(\n",
    "                \"sentiment-analysis\",\n",
    "                model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "            )\n",
    "    \n",
    "    def get_news_articles(self, ticker_symbol: str, company_name: str = None, \n",
    "                         days_back: int = 7, page_size: int = 100) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Fetch news articles for a given stock ticker.\n",
    "        \n",
    "        Args:\n",
    "            ticker_symbol (str): Stock ticker symbol (e.g., 'AAPL')\n",
    "            company_name (str): Company name for better search results\n",
    "            days_back (int): Number of days to look back for news\n",
    "            page_size (int): Number of articles to fetch (max 100)\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: List of news articles\n",
    "        \"\"\"\n",
    "        # Calculate date range\n",
    "        to_date = datetime.now()\n",
    "        from_date = to_date - timedelta(days=days_back)\n",
    "        \n",
    "        # Construct search query\n",
    "        if company_name:\n",
    "            query = f'\"{ticker_symbol}\" OR \"{company_name}\"'\n",
    "        else:\n",
    "            query = f'\"{ticker_symbol}\"'\n",
    "        \n",
    "        # API parameters\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'apiKey': self.news_api_key,\n",
    "            'language': 'en',\n",
    "            'sortBy': 'relevancy',\n",
    "            'pageSize': min(page_size, 100),\n",
    "            'from': from_date.strftime('%Y-%m-%d'),\n",
    "            'to': to_date.strftime('%Y-%m-%d')\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            if data['status'] == 'ok':\n",
    "                articles = data.get('articles', [])\n",
    "                logger.info(f\"Fetched {len(articles)} articles for {ticker_symbol}\")\n",
    "                return articles\n",
    "            else:\n",
    "                logger.error(f\"API error: {data.get('message', 'Unknown error')}\")\n",
    "                return []\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Request failed for {ticker_symbol}: {e}\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error for {ticker_symbol}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def analyze_text_sentiment(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze sentiment of a single text using HuggingFace model.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Text to analyze\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Sentiment analysis results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Truncate text if too long (BERT models have token limits)\n",
    "            max_length = 512\n",
    "            if len(text.split()) > max_length:\n",
    "                text = ' '.join(text.split()[:max_length])\n",
    "            \n",
    "            # Get sentiment prediction\n",
    "            result = self.sentiment_analyzer(text)[0]\n",
    "            \n",
    "            # Normalize labels (different models use different labels)\n",
    "            label = result['label'].upper()\n",
    "            score = result['score']\n",
    "            \n",
    "            # Map different model outputs to consistent labels\n",
    "            if 'POSITIVE' in label or 'POS' in label:\n",
    "                sentiment = 'positive'\n",
    "            elif 'NEGATIVE' in label or 'NEG' in label:\n",
    "                sentiment = 'negative'\n",
    "            else:\n",
    "                sentiment = 'neutral'\n",
    "            \n",
    "            return {\n",
    "                'sentiment': sentiment,\n",
    "                'confidence': score,\n",
    "                'raw_label': result['label']\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Sentiment analysis failed: {e}\")\n",
    "            return {\n",
    "                'sentiment': 'neutral',\n",
    "                'confidence': 0.0,\n",
    "                'raw_label': 'error'\n",
    "            }\n",
    "    \n",
    "    def analyze_articles_sentiment(self, articles: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze sentiment for a list of news articles.\n",
    "        \n",
    "        Args:\n",
    "            articles (List[Dict]): List of news articles\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Aggregated sentiment analysis\n",
    "        \"\"\"\n",
    "        if not articles:\n",
    "            return {\n",
    "                'overall_sentiment': 'neutral',\n",
    "                'sentiment_score': 0.0,\n",
    "                'positive_count': 0,\n",
    "                'negative_count': 0,\n",
    "                'neutral_count': 0,\n",
    "                'total_articles': 0,\n",
    "                'confidence': 0.0\n",
    "            }\n",
    "        \n",
    "        sentiments = []\n",
    "        sentiment_scores = []\n",
    "        \n",
    "        for article in articles:\n",
    "            # Combine title and description for analysis\n",
    "            text_to_analyze = \"\"\n",
    "            if article.get('title'):\n",
    "                text_to_analyze += article['title'] + \" \"\n",
    "            if article.get('description'):\n",
    "                text_to_analyze += article['description']\n",
    "            \n",
    "            if text_to_analyze.strip():\n",
    "                sentiment_result = self.analyze_text_sentiment(text_to_analyze)\n",
    "                sentiments.append(sentiment_result['sentiment'])\n",
    "                \n",
    "                # Convert sentiment to numerical score\n",
    "                if sentiment_result['sentiment'] == 'positive':\n",
    "                    score = sentiment_result['confidence']\n",
    "                elif sentiment_result['sentiment'] == 'negative':\n",
    "                    score = -sentiment_result['confidence']\n",
    "                else:\n",
    "                    score = 0.0\n",
    "                \n",
    "                sentiment_scores.append(score)\n",
    "        \n",
    "        # Calculate aggregated metrics\n",
    "        positive_count = sentiments.count('positive')\n",
    "        negative_count = sentiments.count('negative')\n",
    "        neutral_count = sentiments.count('neutral')\n",
    "        total_articles = len(sentiments)\n",
    "        \n",
    "        # Calculate overall sentiment score (average)\n",
    "        overall_score = np.mean(sentiment_scores) if sentiment_scores else 0.0\n",
    "        \n",
    "        # Determine overall sentiment\n",
    "        if overall_score > 0.1:\n",
    "            overall_sentiment = 'positive'\n",
    "        elif overall_score < -0.1:\n",
    "            overall_sentiment = 'negative'\n",
    "        else:\n",
    "            overall_sentiment = 'neutral'\n",
    "        \n",
    "        # Calculate confidence as standard deviation (lower = more confident)\n",
    "        confidence = 1 - (np.std(sentiment_scores) if len(sentiment_scores) > 1 else 0)\n",
    "        confidence = max(0, min(1, confidence))  # Clamp between 0 and 1\n",
    "        \n",
    "        return {\n",
    "            'overall_sentiment': overall_sentiment,\n",
    "            'sentiment_score': round(overall_score, 3),\n",
    "            'positive_count': positive_count,\n",
    "            'negative_count': negative_count,\n",
    "            'neutral_count': neutral_count,\n",
    "            'total_articles': total_articles,\n",
    "            'confidence': round(confidence, 3)\n",
    "        }\n",
    "    \n",
    "    def get_stock_sentiment(self, ticker_symbol: str, company_name: str = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get complete sentiment analysis for a stock.\n",
    "        \n",
    "        Args:\n",
    "            ticker_symbol (str): Stock ticker symbol\n",
    "            company_name (str): Company name (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Complete sentiment analysis results\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting sentiment analysis for {ticker_symbol}\")\n",
    "        \n",
    "        # Fetch news articles\n",
    "        articles = self.get_news_articles(ticker_symbol, company_name)\n",
    "        \n",
    "        # Analyze sentiment\n",
    "        sentiment_results = self.analyze_articles_sentiment(articles)\n",
    "        \n",
    "        # Add metadata\n",
    "        sentiment_results.update({\n",
    "            'ticker': ticker_symbol,\n",
    "            'company_name': company_name,\n",
    "            'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'articles_analyzed': len(articles)\n",
    "        })\n",
    "        \n",
    "        return sentiment_results\n",
    "\n",
    "def analyze_multiple_stocks(tickers: List[str], news_api_key: str, \n",
    "                          company_names: Dict[str, str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze sentiment for multiple stocks and return as DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        tickers (List[str]): List of ticker symbols\n",
    "        news_api_key (str): NewsAPI key\n",
    "        company_names (Dict[str, str]): Optional mapping of ticker to company name\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Sentiment analysis results for all stocks\n",
    "    \"\"\"\n",
    "    analyzer = StockSentimentAnalyzer(news_api_key)\n",
    "    results = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        company_name = company_names.get(ticker) if company_names else None\n",
    "        \n",
    "        try:\n",
    "            sentiment_data = analyzer.get_stock_sentiment(ticker, company_name)\n",
    "            results.append(sentiment_data)\n",
    "            \n",
    "            # Add delay to respect API rate limits\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to analyze {ticker}: {e}\")\n",
    "            # Add error record\n",
    "            results.append({\n",
    "                'ticker': ticker,\n",
    "                'overall_sentiment': 'neutral',\n",
    "                'sentiment_score': 0.0,\n",
    "                'total_articles': 0,\n",
    "                'confidence': 0.0,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage and integration function\n",
    "def add_sentiment_to_stock_data(df_stocks: pd.DataFrame, news_api_key: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add sentiment analysis to existing stock DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df_stocks (pd.DataFrame): Existing stock data with 'Ticker' column\n",
    "        news_api_key (str): NewsAPI key\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Stock data with sentiment columns added\n",
    "    \"\"\"\n",
    "    # Extract tickers from the DataFrame\n",
    "    tickers = df_stocks['Ticker'].tolist()\n",
    "    \n",
    "    # Get company names if available\n",
    "    company_names = {}\n",
    "    if 'Company_Name' in df_stocks.columns:\n",
    "        company_names = dict(zip(df_stocks['Ticker'], df_stocks['Company_Name']))\n",
    "    \n",
    "    # Analyze sentiment\n",
    "    sentiment_df = analyze_multiple_stocks(tickers, news_api_key, company_names)\n",
    "    \n",
    "    # Merge with original data\n",
    "    sentiment_columns = [\n",
    "        'overall_sentiment', 'sentiment_score', 'positive_count', \n",
    "        'negative_count', 'neutral_count', 'total_articles', 'confidence'\n",
    "    ]\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    sentiment_df_renamed = sentiment_df[['ticker'] + sentiment_columns].rename(columns={\n",
    "        'ticker': 'Ticker',\n",
    "        'overall_sentiment': 'News_Sentiment',\n",
    "        'sentiment_score': 'Sentiment_Score',\n",
    "        'positive_count': 'Positive_Articles',\n",
    "        'negative_count': 'Negative_Articles',\n",
    "        'neutral_count': 'Neutral_Articles',\n",
    "        'total_articles': 'Total_Articles',\n",
    "        'confidence': 'Sentiment_Confidence'\n",
    "    })\n",
    "    \n",
    "    # Merge with original DataFrame\n",
    "    df_with_sentiment = df_stocks.merge(sentiment_df_renamed, on='Ticker', how='left')\n",
    "    \n",
    "    return df_with_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52eeafc3cdb44928bb0a6bcbf6f53c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c797107579e446c9c2780ff93ad699c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157717051ac8440c9b206a310de5e7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e32a838a9c245eab060dbcdf1aef331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c52d84c0164b0eb5f92c570167fae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70dbc03d468464783978e60cd1fa388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:FinBERT model loaded successfully\n",
      "INFO:__main__:Starting sentiment analysis for AAPL\n",
      "INFO:__main__:Fetched 100 articles for AAPL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Stock Analysis:\n",
      "{'overall_sentiment': 'neutral', 'sentiment_score': np.float64(-0.071), 'positive_count': 23, 'negative_count': 30, 'neutral_count': 47, 'total_articles': 100, 'confidence': np.float64(0.356), 'ticker': 'AAPL', 'company_name': 'Apple Inc', 'analysis_date': '2025-06-27 20:26:39', 'articles_analyzed': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "INFO:__main__:FinBERT model loaded successfully\n",
      "INFO:__main__:Starting sentiment analysis for AAPL\n",
      "INFO:__main__:Fetched 100 articles for AAPL\n",
      "INFO:__main__:Starting sentiment analysis for GOOGL\n",
      "INFO:__main__:Fetched 100 articles for GOOGL\n",
      "INFO:__main__:Starting sentiment analysis for MSFT\n",
      "INFO:__main__:Fetched 100 articles for MSFT\n",
      "INFO:__main__:Starting sentiment analysis for TSLA\n",
      "INFO:__main__:Fetched 100 articles for TSLA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiple Stocks Analysis:\n",
      "  ticker overall_sentiment  sentiment_score  total_articles\n",
      "0   AAPL           neutral           -0.071             100\n",
      "1  GOOGL           neutral            0.037             100\n",
      "2   MSFT           neutral           -0.075             100\n",
      "3   TSLA          negative           -0.173             100\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Your NewsAPI key\n",
    "    API_KEY = 'a101780fac934cd6bf8fad7ddff97331'\n",
    "    \n",
    "    # Example: Analyze single stock\n",
    "    analyzer = StockSentimentAnalyzer(API_KEY)\n",
    "    result = analyzer.get_stock_sentiment('AAPL', 'Apple Inc')\n",
    "    print(\"Single Stock Analysis:\")\n",
    "    print(result)\n",
    "    \n",
    "    # Example: Analyze multiple stocks\n",
    "    test_tickers = ['AAPL', 'GOOGL', 'MSFT', 'TSLA']\n",
    "    test_company_names = {\n",
    "        'AAPL': 'Apple Inc',\n",
    "        'GOOGL': 'Google',\n",
    "        'MSFT': 'Microsoft',\n",
    "        'TSLA': 'Tesla'\n",
    "    }\n",
    "    \n",
    "    sentiment_df = analyze_multiple_stocks(test_tickers, API_KEY, test_company_names)\n",
    "    print(\"\\nMultiple Stocks Analysis:\")\n",
    "    print(sentiment_df[['ticker', 'overall_sentiment', 'sentiment_score', 'total_articles']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
