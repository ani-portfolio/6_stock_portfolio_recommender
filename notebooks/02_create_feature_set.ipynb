{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Optional\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tickers(url):\n",
    "    \"\"\"Fetches base data from a given URL and returns it as a DataFrame.\n",
    "    Args:\n",
    "        url (str): The URL to fetch the data from.\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the fetched data.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_html(url)[0]\n",
    "    df = df.rename(columns={'Symbol': 'Ticker', 'Security': 'Company_Name', 'GICS Sector': 'Sector', 'GICS Sub-Industry': 'Industry', 'Founded': 'Founded_Year'}).drop(['Date added', 'CIK'], axis=1)\n",
    "    df.columns = df.columns.str.replace(' ', '_').str.replace('/', '_').str.replace('-', '_')\n",
    "    df['Ticker'] = df['Ticker'].str.upper()\n",
    "    \n",
    "    print(f\"Fetched {len(df)} rows from {url}\")\n",
    "    return df['Ticker'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(ticker_symbol: str, period: str = \"5y\", benchmark_data: Optional[pd.DataFrame] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive stock metrics for a given ticker.\n",
    "    \n",
    "    Args:\n",
    "        ticker_symbol (str): Stock ticker symbol (e.g., 'AAPL')\n",
    "        period (str): Historical data period (default: '5y')\n",
    "        benchmark_data (pd.DataFrame): Pre-loaded S&P 500 data for beta calculation\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Dictionary containing all calculated metrics for the ticker\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "        \n",
    "        # Get historical data\n",
    "        hist = ticker.history(period=period)\n",
    "        if hist.empty:\n",
    "            raise ValueError(f\"No data found for {ticker_symbol}\")\n",
    "        \n",
    "        hist = hist.reset_index()\n",
    "        hist['Date'] = pd.to_datetime(hist['Date'])\n",
    "        hist['Year'] = hist['Date'].dt.year\n",
    "        \n",
    "        # Get ticker info\n",
    "        info = ticker.info\n",
    "        current_year = hist['Year'].max()\n",
    "        \n",
    "        # Initialize results dictionary\n",
    "        stock_data = {'Ticker': ticker_symbol}\n",
    "        \n",
    "        # Price-based metrics\n",
    "        stock_data.update(_calculate_price_metrics(hist))\n",
    "        \n",
    "        # Return calculations\n",
    "        stock_data.update(_calculate_returns(hist, current_year))\n",
    "        \n",
    "        # Risk metrics (pass benchmark_data to avoid reloading)\n",
    "        stock_data.update(_calculate_risk_metrics(hist, benchmark_data))\n",
    "        \n",
    "        # Market data\n",
    "        stock_data.update(_get_market_data(info))\n",
    "        \n",
    "        return stock_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker_symbol}: {e}\")\n",
    "\n",
    "def _calculate_price_metrics(hist: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Calculate price-related metrics.\"\"\"\n",
    "    closing_price = hist['Close'].iloc[-1]\n",
    "    all_time_high = hist['Close'].max()\n",
    "    \n",
    "    # Calculate moving average\n",
    "    hist['200_Day_Moving_Average'] = hist['Close'].rolling(window=200).mean()\n",
    "    \n",
    "    return {\n",
    "        'Closing_Price': round(closing_price, 2),\n",
    "        'All_Time_High': round(all_time_high, 2),\n",
    "        'Percent_From_All_Time_High': round(((closing_price - all_time_high) / all_time_high) * 100, 2),\n",
    "        'Percent_Difference_200_Day_Moving_Average': round(((closing_price - hist['200_Day_Moving_Average'].iloc[-1]) / hist['200_Day_Moving_Average'].iloc[-1]) * 100, 2),\n",
    "        '24_Hour_Percent_Change': round(hist['Close'].pct_change(periods=1).iloc[-1] * 100, 2),\n",
    "        '7_Day_Percent_Change': round(hist['Close'].pct_change(periods=7).iloc[-1] * 100, 2),\n",
    "        '30_Day_Percent_Change': round(hist['Close'].pct_change(periods=30).iloc[-1] * 100, 2)\n",
    "    }\n",
    "\n",
    "\n",
    "def _calculate_returns(hist: pd.DataFrame, current_year: int) -> Dict:\n",
    "    \"\"\"Calculate return metrics.\"\"\"\n",
    "    returns_data = {}\n",
    "    \n",
    "    # Annualized return\n",
    "    total_years = len(hist['Year'].unique())\n",
    "    if total_years > 1:\n",
    "        annualized_return = ((hist['Close'].iloc[-1] / hist['Close'].iloc[0]) ** (1 / total_years) - 1) * 100\n",
    "        returns_data['Annualized_Return'] = round(annualized_return, 2)\n",
    "    \n",
    "    # Yearly returns\n",
    "    for year in sorted(hist['Year'].unique(), reverse=True):\n",
    "        year_data = hist[hist['Year'] == year]\n",
    "        if len(year_data) > 1:\n",
    "            year_return = ((year_data['Close'].iloc[-1] - year_data['Close'].iloc[0]) / year_data['Close'].iloc[0]) * 100\n",
    "            \n",
    "            if year == current_year:\n",
    "                returns_data['YTD_Return'] = round(year_return, 2)\n",
    "            else:\n",
    "                returns_data[f'{year}_Return'] = round(year_return, 2)\n",
    "    \n",
    "    return returns_data\n",
    "\n",
    "\n",
    "def _calculate_risk_metrics(hist: pd.DataFrame, benchmark_data: Optional[pd.DataFrame] = None) -> Dict:\n",
    "    \"\"\"Calculate risk-related metrics.\"\"\"\n",
    "    # Daily returns\n",
    "    hist['Daily_Return'] = hist['Close'].pct_change().dropna()\n",
    "    \n",
    "    # Volatility (annualized)\n",
    "    volatility = hist['Daily_Return'].std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe ratio (assuming 1% risk-free rate)\n",
    "    risk_free_rate = 0.01\n",
    "    if len(hist) > 1:\n",
    "        total_return = (hist['Close'].iloc[-1] / hist['Close'].iloc[0]) - 1\n",
    "        annualized_return = (1 + total_return) ** (252 / len(hist)) - 1\n",
    "        excess_return = annualized_return - risk_free_rate\n",
    "        sharpe_ratio = excess_return / volatility if volatility > 0 else 0\n",
    "    else:\n",
    "        sharpe_ratio = 0\n",
    "    \n",
    "    # Beta calculation (use pre-loaded benchmark data if available)\n",
    "    beta = _calculate_beta(hist, benchmark_data)\n",
    "    \n",
    "    return {\n",
    "        'Annualized_Volatility': round(volatility * 100, 2),\n",
    "        'Sharpe_Ratio': round(sharpe_ratio, 2),\n",
    "        'Beta': round(beta, 2) if not np.isnan(beta) else None\n",
    "    }\n",
    "\n",
    "\n",
    "def _calculate_beta(hist: pd.DataFrame, benchmark_data: Optional[pd.DataFrame] = None) -> float:\n",
    "    \"\"\"Calculate beta against S&P 500 using pre-loaded benchmark data.\"\"\"\n",
    "    try:\n",
    "        if benchmark_data is None:\n",
    "            return np.nan\n",
    "            \n",
    "        # Merge on date\n",
    "        merged = hist.merge(\n",
    "            benchmark_data[['Date', 'Daily_Return']], \n",
    "            on='Date', \n",
    "            suffixes=('', '_Benchmark'),\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        if len(merged) < 30:  # Need sufficient data points\n",
    "            return np.nan\n",
    "        \n",
    "        # Calculate beta using numpy for speed\n",
    "        stock_returns = merged['Daily_Return'].dropna()\n",
    "        benchmark_returns = merged['Daily_Return_Benchmark'].dropna()\n",
    "        \n",
    "        if len(stock_returns) == len(benchmark_returns) and len(stock_returns) > 0:\n",
    "            covariance = np.cov(stock_returns, benchmark_returns)[0, 1]\n",
    "            benchmark_variance = np.var(benchmark_returns)\n",
    "            return covariance / benchmark_variance if benchmark_variance != 0 else np.nan\n",
    "        \n",
    "        return np.nan\n",
    "        \n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def _load_benchmark_data(period: str = \"5y\") -> pd.DataFrame:\n",
    "    \"\"\"Load S&P 500 benchmark data once for all calculations.\"\"\"\n",
    "    try:\n",
    "        print(\"Loading S&P 500 benchmark data...\")\n",
    "        benchmark = yf.Ticker('^GSPC')\n",
    "        benchmark_hist = benchmark.history(period=period).reset_index()\n",
    "        benchmark_hist['Date'] = pd.to_datetime(benchmark_hist['Date'])\n",
    "        benchmark_hist['Daily_Return'] = benchmark_hist['Close'].pct_change()\n",
    "        return benchmark_hist[['Date', 'Daily_Return']].dropna()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load benchmark data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def _get_market_data(info: Dict) -> Dict:\n",
    "    \"\"\"Extract market data from ticker info.\"\"\"\n",
    "    return {\n",
    "        'Company_Name': info.get('shortName', '').replace('\\n', ' '),\n",
    "        'Market_Cap': info.get('marketCap'),\n",
    "        'Sector': info.get('sector'),\n",
    "        'Industry': info.get('industry'),\n",
    "        'Country': info.get('country'),\n",
    "        'Business_Summary': info.get('longBusinessSummary', '').replace('\\n', ' '),\n",
    "        'Dividend_Yield': info.get('dividendYield'),\n",
    "        'Trailing_PE': info.get('trailingPE'),\n",
    "        'Forward_PE': info.get('forwardPE'),\n",
    "        'Average_Volume': info.get('averageVolume'),\n",
    "        'Average_Volume_10days': info.get('averageVolume10days'),\n",
    "        '52_Week_Change': info.get('52WeekChange')\n",
    "    }\n",
    "\n",
    "\n",
    "def get_multiple_stocks_data(tickers: list, period: str = \"5y\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get stock data for multiple tickers and return as DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        tickers (list): List of ticker symbols\n",
    "        period (str): Historical data period\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with stock data for all tickers\n",
    "    \"\"\"\n",
    "    # Pre-load benchmark data once for all stocks\n",
    "    benchmark_data = _load_benchmark_data(period)\n",
    "    \n",
    "    all_data = []\n",
    "\n",
    "    for ticker in (tickers):\n",
    "        try:\n",
    "            stock_data = get_stock_data(ticker)  # your existing function\n",
    "            if stock_data is not None:  # Only append if data was successfully retrieved\n",
    "                tqdm.write(f'Processing {ticker}')\n",
    "                all_data.append(stock_data)\n",
    "            else:\n",
    "                tqdm.write(f\"Warning: No data retrieved for {ticker}\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error processing {ticker}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Clean up Missing Values\n",
    "    df['Dividend_Yield'] = df['Dividend_Yield'].fillna(0)\n",
    "    df['Sector'] = df['Sector'].fillna('Unknown')\n",
    "    df['Industry'] = df['Industry'].fillna('Unknown') \n",
    "    df['Country'] = df['Country'].fillna('Unknown')\n",
    "    df['Business_Summary'] = df['Business_Summary'].fillna('No description available')\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    return df.sort_values('Market_Cap', ascending=False, na_position='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_tickers = get_tickers('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "len(stock_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset with Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched_stock_data = get_multiple_stocks_data(stock_tickers)\n",
    "df_enriched_stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched_stock_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_enriched_stock_data.isna().sum().sum() == 0, \"DataFrame contains NaN values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched_stock_data.to_csv('/Users/ani/Projects/6_stock_portfolio_recommendation/data/enriched_stock_data.csv', index=False)\n",
    "print(\"Enriched stock data saved to 'data/enriched_stock_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
